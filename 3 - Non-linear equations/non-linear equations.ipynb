{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Introduction](#toc1_)    \n",
    "- 2. [Derivative based methods](#toc2_)    \n",
    "- 3. [Numerical derivative](#toc3_)    \n",
    "- 4. [Another example](#toc4_)    \n",
    "- 5. [Derivative free methods: Bisection](#toc5_)    \n",
    "- 6. [Scipy](#toc6_)    \n",
    "- 7. [Non-linear equation systems](#toc7_)    \n",
    "  - 7.1. [Introduction](#toc7_1_)    \n",
    "  - 7.2. [Newton's method](#toc7_2_)    \n",
    "  - 7.3. [Using Scipy](#toc7_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will learn to find roots of non-linear equations numerically (**scipy.optimize**)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**scipy.optimize:** [overview](https://docs.scipy.org/doc/scipy/reference/optimize.html) + [turtorial](https://docs.scipy.org/doc/scipy/tutorial/optimize.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\"axes.grid\":True,\"grid.color\":\"black\",\"grid.alpha\":\"0.25\",\"grid.linestyle\":\"--\"})\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The algorithms written here are meant to be illustrative. The scipy implementations are always both the *fastest* and the *safest* choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id='toc1_'></a>[Introduction](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In economics, we really like setting **First Order Conditions** to 0. We do it every time we want to solve for optimal behavior.\n",
    "\n",
    "Considering the FOCs as separate equations, finding optimal behavior is the same as finding the **root** of the FOCs.\n",
    "\n",
    "Therefore, we often want to **solve non-linear equations** on the form,\n",
    "\n",
    "$$ \n",
    "f(x) = 0, x \\in \\mathbb{R} \n",
    "$$\n",
    "\n",
    "There are 2 ways of going about: \n",
    "* **Using a derivative based method:** Is more robust and takes fever steps.\n",
    "* **Derivative free methods:** Less numerically stable, but does not require a gradient, so often easier to implement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple **example** of a function for our root finding:\n",
    "\n",
    "$$\n",
    "f(x) = -x^3 + 2x^2 + 4x + 30 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[Derivative based methods](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newton methods:**  \n",
    "\n",
    "1. Basic assumption: you know the function value *and* derivatives at a point $x_0$.   \n",
    "2. We now want to know what point $x^*$ gives a root of the function.\n",
    "\n",
    "**Importantly** since we are looking for a root, we know that $f(x^*) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a **first order** Taylor approximation of the function at a **new point** $x_k$ to search for the root of $f$:\n",
    "\n",
    "$$ \n",
    "f(x_k) \\approx f(x_0) + f^{\\prime}(x_0)(x_k-x_0)\n",
    "$$\n",
    "\n",
    "implying that if $x_k$ is the root, we have\n",
    "\n",
    "$$\n",
    "f(x_k) = 0 \\Leftrightarrow x_k = x_0 - \\frac{f(x_0)}{f^{\\prime}(x_0)}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called **Newton's method**.   \n",
    "\n",
    "You can think of it as an **operator** on $x$ with respect to $f$ used to find the **nearest** root of $f$.  \n",
    "\n",
    "Let's call the operator $\\mathcal{N}_f$. If our current guess of a root to $f$ is $x_k$, we can get a new guess $x_{k+1}$ by applying $\\mathcal{N}_f(x_k)$\n",
    "* $x_1 = \\mathcal{N}_f(x_0) =  x_0 - \\frac{f(x_0)}{f^{\\prime}(x_0)}$\n",
    "* $x_2 = \\mathcal{N}_f(x_1)$\n",
    "* $x_3 = \\mathcal{N}_f(x_2)$\n",
    "* ...\n",
    "\n",
    "We have found a root when $|f(x_{k})| < \\epsilon$ which implies that the consecutive guesses also will become very close: $|x_{k+1}-x_k| < \\epsilon$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm:** `find_root()`\n",
    "\n",
    "1. Choose tolerance $\\epsilon > 0$, guess on $x_0$ and set $k = 0$.\n",
    "2. Calculate $f(x_k)$ and $f^{\\prime}(x_k)$.\n",
    "3. If $|f(x_k)| < \\epsilon$ then stop.\n",
    "4. Calculate new candidate $x_{k+1} = \\mathcal{N}_f(x_k)$.\n",
    "5. Set $k = k + 1$ and return to step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root(x0,f,df,max_iter=500,tol=1e-8,full_info=False):\n",
    "    \"\"\" find root\n",
    "        \n",
    "    Args:\n",
    "    \n",
    "        x0 (float): initial value\n",
    "        f (callable): function\n",
    "        df (callable): derivative\n",
    "        max_iter (int): maximum number of iterations\n",
    "        tol (float): tolerance\n",
    "        full_info (bool): controls information returned\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        x (float/ndarray): root (if full_info, all x tried)\n",
    "        k (int): number of iterations used\n",
    "        fx (ndarray): function values used (if full_info) \n",
    "        fpx (ndarray): derivative values used (if full_info)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize\n",
    "    xs = []\n",
    "    fxs = []\n",
    "    dfxs = []\n",
    "    \n",
    "    # iterate\n",
    "    x_k = x0    \n",
    "    k = 0    \n",
    "    while True:\n",
    "        \n",
    "        x = x_k\n",
    "\n",
    "        # step 2: evaluate function and derivatives\n",
    "        fx = f(x)\n",
    "        dfx = df(x)\n",
    "        \n",
    "        # store info\n",
    "        xs.append(x)\n",
    "        fxs.append(fx)\n",
    "        dfxs.append(dfx)\n",
    "\n",
    "        # step 3: check convergence\n",
    "        if abs(fx) < tol or k >= max_iter:\n",
    "            break\n",
    "            \n",
    "        # step 4: update x\n",
    "        x_k = x - fx/dfx\n",
    "        \n",
    "        # step 5: increment counter\n",
    "        k += 1\n",
    "        \n",
    "    # return\n",
    "    if full_info:\n",
    "        return np.array(xs),k,np.array(fxs),np.array(dfxs)\n",
    "    else:\n",
    "        return x,k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pause:** Spend some time looking at the function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The cell below contains a function for plotting the convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_find_root(x0,f,fp,xmin=-8,xmax=8,xn=100):\n",
    "    \n",
    "    # a. find root and return all information \n",
    "    x,max_iter,fx,fpx = find_root(x0,f,df=fp,full_info=True)\n",
    "    \n",
    "    # b. compute function on grid\n",
    "    xvec = np.linspace(xmin,xmax,xn)\n",
    "    fxvec = f(xvec)\n",
    "    \n",
    "    # c. figure\n",
    "    def _figure(k):\n",
    "        \n",
    "        # i. approximation\n",
    "        fapprox = fx[k] + fpx[k]*(xvec-x[k])\n",
    "            \n",
    "        # ii. figure\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        \n",
    "        ax.plot(xvec,fxvec) # on grid\n",
    "        ax.plot(x[k],0,'o',color='blue',mfc='none',label='$x_{k}$')# now\n",
    "        ax.plot(xvec,fapprox) # approximation\n",
    "        ax.plot(x[k],fx[k],'o',color='black',label='$f(x_k)$') # now       \n",
    "\n",
    "        ax.axhline(0,ls='-',lw=1,color='black') # coordinate system\n",
    "        ax.axvline(0,ls='-',lw=1,color='black') # coordinate system\n",
    "        \n",
    "        if k+1 < len(x):\n",
    "            ax.axvline(x[k+1],ls='--',lw=1,color='black') # cross zero\n",
    "            ax.plot(x[k+1],0,'o',color='green',mfc='none',label='$x_{k+1}$') # next\n",
    "                \n",
    "        ax.legend(loc='upper left',facecolor='white',ncols=3,frameon=True)\n",
    "        ax.set_ylim([fxvec[0],fxvec[-1]])\n",
    "    \n",
    "    widgets.interact(_figure,\n",
    "        k=widgets.IntSlider(description=\"iterations\", min=0, max=max_iter, step=1, value=0)\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrating rootfinding by Newton's methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: -x**3 + 2*(x**2) + 4*x + 30 \n",
    "df = lambda x: -3*(x**2) + 4*x + 4\n",
    "df2 = lambda x: -6*x + 4 \n",
    "x0 = -5.0\n",
    "\n",
    "x,k = find_root(x0,f,df)\n",
    "print(f'x = {x:.8f} [iterations: {k}]')\n",
    "print(f'f(x) = {f(x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_find_root(x0,f,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a id='toc3_'></a>[Numerical derivative](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you might not have the **analytical derivative**. Then, you can instead use the **numerical derivative**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical derivative:** Define $\\Delta$ to be a small number, then we approximate the derivative by \n",
    "$$\n",
    " \\frac{df}{dx} \\approx \\frac{f(x+\\Delta) - f(x)}{\\Delta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. numerical derivative (forward)\n",
    "Delta = 1e-8\n",
    "fp_approx = lambda x: (f(x+Delta)-f(x))/Delta\n",
    "\n",
    "# b. find root\n",
    "x0 = -5.0\n",
    "x,i = find_root(x0,f,fp_approx)\n",
    "print(f'iterations: {i}, root: {x}, f(x) = {f(x)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What happens if you increase the stepsize to 1?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a id='toc4_'></a>[Another example](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda x: np.sin(x)\n",
    "gp = lambda x: np.cos(x)\n",
    "\n",
    "x0 = 4.0\n",
    "plot_find_root(x0,g,gp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What happens if the initial value is -2?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a id='toc5_'></a>[Derivative free methods: Bisection](#toc0_)\n",
    "\n",
    "Bisection is, like Newton's, an important root finding algorithm.\n",
    "\n",
    "Look at the graph below. If $f(a) \\times f(b) < 0$ then there must be a root in between $a$ and $b$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a. x-values and function-values\n",
    "xs = np.linspace(-8,8,100)\n",
    "ys = f(xs)\n",
    "\n",
    "# b. figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(xs,ys)\n",
    "ax.axhline(0, ls='-',lw=1,color='black')\n",
    "ax.plot(xs[0],ys[0],'o',color='blue',label='$f(a)$')\n",
    "ax.plot(xs[-1],ys[-1],'o',color='green',label='$f(b)$')\n",
    "ax.legend(loc='lower left',facecolor='white',frameon=True);\n",
    "ax.grid(visible=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm:** `bisection()`\n",
    "\n",
    "1. Set $a_0 = a$ and $b_0 = b$ where $f(a)$ and $f(b)$ has oposite sign, $f(a_0)f(b_0)<0$\n",
    "2. Compute $f(m_0)$ where $m_0 = (a_0 + b_0)/2$ is the midpoint.\n",
    "3. Determine the next sub-interval $[a_1,b_1]$:\n",
    "  * If $f(a_0)f(m_0) < 0$ (different signs) then $a_1 = a_0$ and $b_1 = m_0$ (i.e. focus on the range $[a_0,m_0]$).\n",
    "  * If $f(m_0)f(b_0) < 0$ (different signs) then $a_1 = m_0$ and $b_1 = b_0$ (i.e. focus on the range $[m_0,b_0]$).\n",
    "4. Repeat step 2 and step 3 until $f(m_n) < \\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection(f,a,b,max_iter=500,tol=1e-8,full_info=False):\n",
    "    \"\"\" bisection\n",
    "    \n",
    "    Solve equation f(x) = 0 for a <= x <= b.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        f (callable): function\n",
    "        a (float): left bound\n",
    "        b (float): right bound\n",
    "        max_iter (int): maximum number of iterations\n",
    "        tol (float): tolerance on solution\n",
    "        full_info (bool): controls information returned\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        m (float/ndarray): root (if full_info, all x tried)\n",
    "        k (int): number of iterations used\n",
    "        a (ndarray): left bounds used\n",
    "        b (ndarray): right bounds used\n",
    "        fm (ndarray): funciton values at midpoints\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # test inputs\n",
    "    if f(a)*f(b) >= 0:\n",
    "        print(\"bisection method fails.\")\n",
    "        return None\n",
    "    \n",
    "    # initialize\n",
    "    a_l = []\n",
    "    b_l = []\n",
    "    m_l = []\n",
    "    fm_l = []\n",
    "    \n",
    "    # step 2-4: main\n",
    "    k = 0\n",
    "    while k < max_iter:\n",
    "        \n",
    "        # step 2: midpoint and associated value\n",
    "        m = (a+b)/2\n",
    "        fm = f(m)\n",
    "        \n",
    "        # store info\n",
    "        a_l.append(a)\n",
    "        b_l.append(b)\n",
    "        m_l.append(m)\n",
    "        fm_l.append(fm)\n",
    "        \n",
    "        # step 3: determine sub-interval\n",
    "        if abs(fm) < tol:\n",
    "            break        \n",
    "        elif f(a)*fm < 0:\n",
    "            b = m\n",
    "        elif f(b)*fm < 0:\n",
    "            a = m\n",
    "        else:\n",
    "            print(\"bisection method fails.\")\n",
    "            return None\n",
    "        \n",
    "        k += 1\n",
    "        \n",
    "    if full_info:\n",
    "        # Returned lists are converted to np.arrays for good measure\n",
    "        return np.array(m_l), k, np.array(a_l), np.array(b_l), np.array(fm_l)\n",
    "    else:\n",
    "        return m,k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,k = bisection(f,2,7)\n",
    "print(k,m,f(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Same result** as before, but **trade-off** between more iterations and no evaluation of derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pause:** Spend some time looking at the function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The cell below contains a function for plotting the convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bisection(f,a,b,xmin=-8,xmax=8,xn=100):\n",
    "    \n",
    "    # a. find root and return all information \n",
    "    res = bisection(f,a,b,full_info=True)\n",
    "    if res == None:\n",
    "        return\n",
    "    else:\n",
    "        m,max_iter,a,b,fm = res\n",
    "    \n",
    "    # b. compute function on grid\n",
    "    xvec = np.linspace(xmin,xmax,xn)\n",
    "    fxvec = f(xvec)\n",
    "    \n",
    "    # c. figure\n",
    "    def _figure(k):\n",
    "        \n",
    "        # ii. figure\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        \n",
    "        ax.plot(xvec,fxvec) # on grid\n",
    "        ax.axhline(y=0, xmin=xmin, xmax=xmax,color='black')\n",
    "        ax.plot(m[k],fm[k],'o',color='black',label='current') # mid\n",
    "        ax.plot([a[k],b[k]],[fm[k],fm[k]],'--',color='green',label='range') # range\n",
    "        ax.axvline(a[k],ls='--',color='green')\n",
    "        ax.axvline(b[k],ls='--',color='green')        \n",
    "        \n",
    "        ax.legend(loc='lower left',facecolor='white',frameon=True)\n",
    "        ax.set_ylim([fxvec[-1],fxvec[0]])\n",
    "    \n",
    "    widgets.interact(_figure,\n",
    "        k=widgets.IntSlider(description=\"iterations\", min=0, max=max_iter-1, step=1, value=0)\n",
    "    );\n",
    "\n",
    "plot_bisection(f,-8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Note:** Bisection is not good at the final convergence steps. Generally true for methods not using derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. <a id='toc6_'></a>[Scipy](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy, naturally, has better implementations of the above algorithms. \n",
    "\n",
    "You will most likely want to go for these when doing your own model solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newton:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root_scalar(f,x0=-4,fprime=df,method='newton')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Halley:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root_scalar(f,x0=-4,fprime=df,fprime2=df2,method='halley')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bisect:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root_scalar(f,bracket=[-8,7],method='bisect')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **best choice** is the more advanced **Brent-method**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root_scalar(f,bracket=[-8,7],method='brentq')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. <a id='toc7_'></a>[Non-linear equation systems](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. <a id='toc7_1_'></a>[Introduction](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider **solving non-linear equations** on the form,\n",
    "\n",
    "$$ \n",
    "f(\\boldsymbol{x}) = f(x_1,x_2,\\dots,x_k) = \\boldsymbol{0}, \\boldsymbol{x} \\in \\mathbb{R}^k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A specific **example** is:\n",
    "\n",
    "$$ \n",
    "h(\\boldsymbol{x})=h(x_{1,}x_{2})=\\begin{bmatrix}h_{1}(x_{1},x_{2})\\\\\n",
    "h_{2}(x_{1},x_{2})\n",
    "\\end{bmatrix}=\\begin{bmatrix}x_{1}+0.5(x_{1}-x_{2})^{3}-1\\\\\n",
    "x_{2}+0.5(x_{1}-x_{2})^{3}\n",
    "\\end{bmatrix}\\in\\mathbb{R}^{2} \n",
    "$$\n",
    "\n",
    "where the **Jacobian** is\n",
    "\n",
    "$$ \n",
    "\\nabla h(\\boldsymbol{x})=\\begin{bmatrix}\\frac{\\partial h_{1}}{\\partial x_{1}} & \\frac{\\partial h_{1}}{\\partial x_{2}}\\\\\n",
    "\\frac{\\partial h_{2}}{\\partial x_{1}} & \\frac{\\partial h_{2}}{\\partial x_{2}}\n",
    "\\end{bmatrix}=\\begin{bmatrix}1+1.5(x_{1}-x_{2})^{2} & -1.5(x_{1}-x_{2})^{2}\\\\\n",
    "-1.5(x_{2}-x_{1})^{2} & 1+1.5(x_{2}-x_{1})^{2}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x):\n",
    "    y = np.zeros(2)\n",
    "    y[0] = x[0]+0.5*(x[0]-x[1])**3-1.0\n",
    "    y[1] = x[1]+0.5*(x[1]-x[0])**3\n",
    "    return y\n",
    "\n",
    "def hp(x):\n",
    "    y = np.zeros((2,2))\n",
    "    y[0,0] = 1+1.5*(x[0]-x[1])**2\n",
    "    y[0,1] = -1.5*(x[0]-x[1])**2\n",
    "    y[1,0] = -1.5*(x[1]-x[0])**2\n",
    "    y[1,1] = 1+1.5*(x[1]-x[0])**2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. <a id='toc7_2_'></a>[Newton's method](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving a multidimensional system of equations follows the **exact same strategy** as finding the root of a single equation \n",
    "\n",
    "**Except** we are now working with the Jacobian instead of a single derivative. \n",
    "\n",
    "Same as Newton's method in one dimension, but with the following **update step**:\n",
    "\n",
    "$$ \n",
    "\\boldsymbol{x}_{n+1} = \\boldsymbol{x_n} - [ \\nabla h(\\boldsymbol{x_n})]^{-1} f(\\boldsymbol{x_n})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root_multidim(x0,f,fp,max_iter=500,tol=1e-8,use_solve=False):\n",
    "    \"\"\" find root\n",
    "        \n",
    "    Args:\n",
    "    \n",
    "        x0 (float): initial value\n",
    "        f (callable): function\n",
    "        fp (callable): derivative\n",
    "        max_iter (int): maximum number of iterations\n",
    "        tol (float): tolerance\n",
    "        use_solvv (boolean): use linalg.solve in update step\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        x (float): root\n",
    "        k (int): number of iterations used\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize\n",
    "    x = x0\n",
    "    k = 0\n",
    "    \n",
    "    # iterate\n",
    "    while k < max_iter:\n",
    "        \n",
    "        # step 2: function and derivatives\n",
    "        fx = f(x)\n",
    "        fpx = fp(x)\n",
    "        \n",
    "        # step 3: check convergence\n",
    "        if max(abs(fx)) < tol:\n",
    "            break\n",
    "            \n",
    "        # step 4: update x\n",
    "        if use_solve: # numerically more stable\n",
    "            x = linalg.solve(fpx,fpx@x-fx)\n",
    "        else:\n",
    "            fpx_inv = linalg.inv(fpx)        \n",
    "            x = x - fpx_inv@fx\n",
    "        \n",
    "        # step 5: increment counter\n",
    "        k += 1\n",
    "        \n",
    "    return x,k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pause:** Spend some time looking at the function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test algorithm:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0,0])\n",
    "x,k = find_root_multidim(x0,h,hp)\n",
    "print(k,x,h(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0,0])\n",
    "x,k = find_root_multidim(x0,h,hp,use_solve=True)\n",
    "print(k,x,h(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. <a id='toc7_3_'></a>[Using Scipy](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist a lot of efficient algorithms for finding roots in multiple dimensions. The default **scipy** choice is something called ***hybr***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With the Jacobian:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root(h,x0,jac=hp)\n",
    "print(result)\n",
    "print('\\nx =',result.x,', h(x) =',h(result.x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without the Jacobian** (numerical derivative):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root(h,x0)\n",
    "print(result)\n",
    "print('\\nx =',result.x,', h(x) =',h(result.x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "47ef90cdf3004d3f859f1fb202523c65c07ba7c22eefd261b181f4744e2d0403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
